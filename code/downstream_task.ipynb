{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2668a319",
   "metadata": {},
   "source": [
    "# Emotion Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7bbff1",
   "metadata": {},
   "source": [
    "It uses both strategy (1) test set 1: consider all samples corresponding to opportune moment, (2) test set 2: consider all samples regardless of opportune or non-opportune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bde5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load physiological data\n",
    "def load_physiological_data(file_path):\n",
    "    columns = [\"time\", \"ECG\", \"BVP\", \"GSR\", \"Resp\", \"Skin_Temp\", \"EMG_z\", \"EMG_c\", \"EMG_t\"]\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", names=columns)\n",
    "    return df\n",
    "\n",
    "# Load valence-arousal data\n",
    "def load_valence_arousal_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", names=[\"jsttime\", \"valence\", \"arousal\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be98644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample data to 1Hz and create 5-second windows\n",
    "def preprocess_data(physio_df, va_df, window_size=5):\n",
    "    # Downsample physiological data from 1000Hz to 1Hz\n",
    "    physio_downsampled = physio_df.iloc[::1000].copy()  # Simple decimation\n",
    "    \n",
    "    # Downsample valence-arousal data from 20Hz to 1Hz\n",
    "    va_downsampled = va_df.iloc[::20].copy()\n",
    "    \n",
    "    # Create windows for both datasets\n",
    "    start_time = min(physio_downsampled[\"time\"].min(), va_downsampled[\"jsttime\"].min())\n",
    "    \n",
    "    physio_downsampled[\"window\"] = ((physio_downsampled[\"time\"] - start_time) // window_size).astype(int)\n",
    "    va_downsampled[\"window\"] = ((va_downsampled[\"jsttime\"] - start_time) // window_size).astype(int)\n",
    "    \n",
    "    # Aggregate by window\n",
    "    physio_segmented = physio_downsampled.groupby(\"window\").mean().reset_index()\n",
    "    va_segmented = va_downsampled.groupby(\"window\").mean().reset_index()\n",
    "    \n",
    "    return physio_segmented, va_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945c69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuLSIF Algorithm for Change-Point Detection\n",
    "def compute_rulsif_change_scores(X, alpha=0.1, sigma=0.1, lambda_param=1e-3):\n",
    "    n = len(X) - 1\n",
    "    change_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_t, X_t_next = X[i], X[i + 1]\n",
    "        \n",
    "        # Compute Gaussian Kernel Matrix\n",
    "        K_t = rbf_kernel(X_t.reshape(-1, 1), X_t.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        K_t_next = rbf_kernel(X_t_next.reshape(-1, 1), X_t_next.reshape(-1, 1), gamma=1/(2*sigma**2))\n",
    "        \n",
    "        # Compute Weights using Least Squares Importance Fitting (LSIF)\n",
    "        H = alpha * K_t + (1 - alpha) * K_t_next + lambda_param * np.eye(K_t.shape[0])\n",
    "        h = np.mean(K_t, axis=1)\n",
    "        \n",
    "        theta = np.linalg.solve(H, h)\n",
    "        \n",
    "        # Compute Change Score\n",
    "        change_scores[i] = np.mean(np.square(K_t_next.dot(theta) - 1))\n",
    "    \n",
    "    return change_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb29a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify significant changes and label opportune moments\n",
    "def label_opportune_moments(change_scores):\n",
    "    mean, std = np.mean(change_scores), np.std(change_scores)\n",
    "    threshold = mean + 3 * std\n",
    "    outliers = change_scores > threshold\n",
    "    \n",
    "    # Clustering the remaining scores\n",
    "    valid_indices = np.where(~outliers)[0]  # Indices of non-outliers\n",
    "    valid_scores = change_scores[valid_indices]\n",
    "    \n",
    "    if len(valid_scores) > 1:  # Ensure there are enough points for clustering\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42).fit(valid_scores.reshape(-1, 1))\n",
    "        centroids = kmeans.cluster_centers_.flatten()\n",
    "        high_cluster = np.argmax(centroids)\n",
    "        high_values = (kmeans.labels_ == high_cluster) & (valid_scores > centroids[high_cluster])\n",
    "        \n",
    "        # Map high_values back to the original indices\n",
    "        high_values_original = np.zeros_like(change_scores, dtype=bool)\n",
    "        high_values_original[valid_indices] = high_values\n",
    "    else:\n",
    "        # If there are not enough valid scores, treat all as non-opportune\n",
    "        high_values_original = np.zeros_like(change_scores, dtype=bool)\n",
    "    \n",
    "    # Mark opportune moments\n",
    "    opportune_moments = np.where(outliers | high_values_original)[0]\n",
    "    return opportune_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2603b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align valence-arousal data with physiological data windows\n",
    "def align_data(physiological_data, valence_arousal_data, window_size=5):\n",
    "    # Convert jsttime to window index\n",
    "    start_time = physiological_data[\"time\"].min()\n",
    "    valence_arousal_data[\"window\"] = ((valence_arousal_data[\"jsttime\"] - start_time) // window_size).astype(int)\n",
    "    \n",
    "    # Merge data on window index\n",
    "    merged_data = pd.merge(physiological_data, valence_arousal_data, on=\"window\", how=\"inner\")\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2237937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map valence-arousal to emotion classes\n",
    "def map_to_emotion_classes(valence, arousal):\n",
    "    # Define emotion classes based on valence and arousal\n",
    "    if valence >= 0 and arousal >= 0:\n",
    "        return \"Happy\"\n",
    "    elif valence >= 0 and arousal < 0:\n",
    "        return \"Relaxed\"\n",
    "    elif valence < 0 and arousal >= 0:\n",
    "        return \"Stressed\"\n",
    "    else:\n",
    "        return \"Sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075bc50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classification model\n",
    "def train_and_evaluate_classifier(X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.84      0.97      0.90        73\n",
      "     Relaxed       0.67      0.29      0.40        14\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.83        99\n",
      "   macro avg       0.59      0.47      0.51        99\n",
      "weighted avg       0.81      0.83      0.80        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.91      0.86        34\n",
      "     Relaxed       1.00      0.25      0.40         4\n",
      "    Stressed       0.73      0.67      0.70        12\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.85      0.61      0.65        50\n",
      "weighted avg       0.81      0.80      0.78        50\n",
      "\n",
      "Successfully processed User 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.90      0.93      0.92        58\n",
      "     Relaxed       0.82      0.82      0.82        22\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.88      0.83      0.86        18\n",
      "\n",
      "    accuracy                           0.88        99\n",
      "   macro avg       0.65      0.65      0.65        99\n",
      "weighted avg       0.87      0.88      0.87        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.90      0.90      0.90        30\n",
      "     Relaxed       0.71      0.83      0.77        12\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.65      0.65      0.65        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n",
      "Successfully processed User 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.79      0.89      0.84        63\n",
      "     Relaxed       0.76      0.57      0.65        23\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.80      0.67      0.73        12\n",
      "\n",
      "    accuracy                           0.78        99\n",
      "   macro avg       0.59      0.53      0.55        99\n",
      "weighted avg       0.78      0.78      0.77        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.90      0.89        39\n",
      "     Relaxed       0.75      0.60      0.67        10\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.84        55\n",
      "   macro avg       0.61      0.62      0.62        55\n",
      "weighted avg       0.83      0.84      0.83        55\n",
      "\n",
      "Successfully processed User 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.79      0.98      0.88        65\n",
      "     Relaxed       0.33      0.08      0.13        12\n",
      "         Sad       1.00      0.56      0.71         9\n",
      "    Stressed       0.90      0.69      0.78        13\n",
      "\n",
      "    accuracy                           0.80        99\n",
      "   macro avg       0.76      0.58      0.63        99\n",
      "weighted avg       0.77      0.80      0.76        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.74      0.97      0.84        29\n",
      "     Relaxed       0.40      0.20      0.27        10\n",
      "         Sad       0.00      0.00      0.00         3\n",
      "    Stressed       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.51      0.49      0.49        52\n",
      "weighted avg       0.66      0.73      0.68        52\n",
      "\n",
      "Successfully processed User 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.78      0.88      0.83        59\n",
      "     Relaxed       0.67      0.57      0.62        28\n",
      "         Sad       0.00      0.00      0.00         5\n",
      "    Stressed       0.62      0.71      0.67         7\n",
      "\n",
      "    accuracy                           0.74        99\n",
      "   macro avg       0.52      0.54      0.53        99\n",
      "weighted avg       0.70      0.74      0.71        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.80      0.97      0.88        29\n",
      "     Relaxed       0.67      0.62      0.64        13\n",
      "         Sad       1.00      0.33      0.50         3\n",
      "    Stressed       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.84      0.64      0.69        56\n",
      "weighted avg       0.79      0.79      0.77        56\n",
      "\n",
      "Successfully processed User 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.79      0.98      0.88        61\n",
      "     Relaxed       0.93      0.52      0.67        25\n",
      "         Sad       0.80      0.80      0.80         5\n",
      "    Stressed       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.82        99\n",
      "   macro avg       0.88      0.70      0.75        99\n",
      "weighted avg       0.84      0.82      0.80        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.97      0.89        33\n",
      "     Relaxed       0.86      0.67      0.75         9\n",
      "         Sad       1.00      0.57      0.73         7\n",
      "    Stressed       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.92      0.74      0.81        53\n",
      "weighted avg       0.86      0.85      0.84        53\n",
      "\n",
      "Successfully processed User 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.92      0.87        76\n",
      "     Relaxed       0.29      0.15      0.20        13\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.78        99\n",
      "   macro avg       0.46      0.41      0.42        99\n",
      "weighted avg       0.73      0.78      0.75        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.83      0.86        36\n",
      "     Relaxed       0.55      0.60      0.57        10\n",
      "    Stressed       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.77        48\n",
      "   macro avg       0.59      0.64      0.61        48\n",
      "weighted avg       0.79      0.77      0.78        48\n",
      "\n",
      "Successfully processed User 7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.93      0.97      0.95        66\n",
      "     Relaxed       0.89      0.77      0.83        22\n",
      "         Sad       1.00      0.67      0.80         3\n",
      "    Stressed       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.92        99\n",
      "   macro avg       0.93      0.85      0.88        99\n",
      "weighted avg       0.92      0.92      0.92        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.97      0.94      0.95        31\n",
      "     Relaxed       0.80      0.89      0.84         9\n",
      "    Stressed       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.92      0.94      0.93        49\n",
      "weighted avg       0.94      0.94      0.94        49\n",
      "\n",
      "Successfully processed User 8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.75      0.80      0.77        49\n",
      "     Relaxed       0.78      0.70      0.74        40\n",
      "    Stressed       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.74        99\n",
      "   macro avg       0.69      0.70      0.69        99\n",
      "weighted avg       0.74      0.74      0.74        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.77      0.85      0.81        27\n",
      "     Relaxed       0.72      0.65      0.68        20\n",
      "    Stressed       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.77      0.74      0.75        54\n",
      "weighted avg       0.76      0.76      0.76        54\n",
      "\n",
      "Successfully processed User 9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.79      0.94      0.86        64\n",
      "     Relaxed       0.75      0.60      0.67        15\n",
      "         Sad       0.50      0.33      0.40         3\n",
      "    Stressed       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.79        99\n",
      "   macro avg       0.73      0.59      0.63        99\n",
      "weighted avg       0.79      0.79      0.77        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.74      0.97      0.84        29\n",
      "     Relaxed       0.86      0.60      0.71        10\n",
      "         Sad       0.00      0.00      0.00         5\n",
      "    Stressed       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.65      0.60      0.61        50\n",
      "weighted avg       0.72      0.78      0.74        50\n",
      "\n",
      "Successfully processed User 10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.83      0.91      0.87        70\n",
      "     Relaxed       0.65      0.72      0.68        18\n",
      "         Sad       1.00      0.14      0.25         7\n",
      "    Stressed       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.80        99\n",
      "   macro avg       0.87      0.51      0.55        99\n",
      "weighted avg       0.82      0.80      0.77        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.84      0.97      0.90        32\n",
      "     Relaxed       1.00      0.61      0.76        18\n",
      "         Sad       0.25      0.50      0.33         2\n",
      "    Stressed       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.77      0.77      0.75        53\n",
      "weighted avg       0.87      0.83      0.83        53\n",
      "\n",
      "Successfully processed User 11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.86      0.95      0.90        74\n",
      "     Relaxed       0.86      0.40      0.55        15\n",
      "    Stressed       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.85        99\n",
      "   macro avg       0.82      0.72      0.74        99\n",
      "weighted avg       0.85      0.85      0.83        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.84      1.00      0.91        36\n",
      "     Relaxed       0.00      0.00      0.00         6\n",
      "    Stressed       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.61      0.62      0.61        49\n",
      "weighted avg       0.76      0.86      0.80        49\n",
      "\n",
      "Successfully processed User 12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.81      0.93      0.87        70\n",
      "     Relaxed       0.71      0.29      0.42        17\n",
      "         Sad       1.00      0.50      0.67         2\n",
      "    Stressed       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.80        99\n",
      "   macro avg       0.81      0.63      0.68        99\n",
      "weighted avg       0.79      0.80      0.77        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.77      1.00      0.87        34\n",
      "     Relaxed       1.00      0.20      0.33        10\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.69      0.50      0.52        50\n",
      "weighted avg       0.83      0.80      0.75        50\n",
      "\n",
      "Successfully processed User 13\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.86      0.93      0.89        80\n",
      "     Relaxed       0.43      0.20      0.27        15\n",
      "         Sad       0.50      1.00      0.67         2\n",
      "    Stressed       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        99\n",
      "   macro avg       0.45      0.53      0.46        99\n",
      "weighted avg       0.77      0.80      0.78        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.72      0.97      0.83        30\n",
      "     Relaxed       0.88      0.44      0.58        16\n",
      "         Sad       0.50      0.50      0.50         2\n",
      "    Stressed       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.53      0.48      0.48        50\n",
      "weighted avg       0.73      0.74      0.70        50\n",
      "\n",
      "Successfully processed User 14\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.78      0.95      0.86        73\n",
      "     Relaxed       0.60      0.25      0.35        12\n",
      "         Sad       0.67      0.50      0.57         4\n",
      "    Stressed       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.77        99\n",
      "   macro avg       0.68      0.47      0.52        99\n",
      "weighted avg       0.75      0.77      0.73        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.65      0.91      0.76        35\n",
      "     Relaxed       1.00      0.22      0.36         9\n",
      "         Sad       0.00      0.00      0.00         5\n",
      "    Stressed       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.63        57\n",
      "   macro avg       0.51      0.35      0.36        57\n",
      "weighted avg       0.62      0.63      0.57        57\n",
      "\n",
      "Successfully processed User 15\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.92      0.90        71\n",
      "     Relaxed       0.55      0.40      0.46        15\n",
      "         Sad       0.62      1.00      0.77         5\n",
      "    Stressed       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.83        99\n",
      "   macro avg       0.76      0.77      0.75        99\n",
      "weighted avg       0.82      0.83      0.82        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.86      0.89      0.87        35\n",
      "     Relaxed       0.33      0.43      0.38         7\n",
      "         Sad       1.00      0.50      0.67         6\n",
      "    Stressed       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.78        55\n",
      "   macro avg       0.76      0.67      0.69        55\n",
      "weighted avg       0.81      0.78      0.79        55\n",
      "\n",
      "Successfully processed User 16\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.84      0.88      0.86        48\n",
      "     Relaxed       0.71      0.56      0.63        18\n",
      "         Sad       0.64      0.60      0.62        15\n",
      "    Stressed       0.76      0.89      0.82        18\n",
      "\n",
      "    accuracy                           0.78        99\n",
      "   macro avg       0.74      0.73      0.73        99\n",
      "weighted avg       0.77      0.78      0.77        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.76      0.86      0.81        29\n",
      "     Relaxed       0.71      0.56      0.63         9\n",
      "         Sad       0.50      0.50      0.50         8\n",
      "    Stressed       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.74      0.63      0.67        51\n",
      "weighted avg       0.73      0.73      0.72        51\n",
      "\n",
      "Successfully processed User 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.91      0.94      0.92        84\n",
      "     Relaxed       0.58      0.78      0.67         9\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.87        99\n",
      "   macro avg       0.37      0.43      0.40        99\n",
      "weighted avg       0.82      0.87      0.84        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.98      0.92        44\n",
      "     Relaxed       0.00      0.00      0.00         4\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.22      0.24      0.23        50\n",
      "weighted avg       0.77      0.86      0.81        50\n",
      "\n",
      "Successfully processed User 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.93      1.00      0.97        85\n",
      "     Relaxed       0.00      0.00      0.00         4\n",
      "    Stressed       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.93        99\n",
      "   macro avg       0.60      0.57      0.58        99\n",
      "weighted avg       0.89      0.93      0.91        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.91      0.98      0.94        43\n",
      "     Relaxed       0.00      0.00      0.00         4\n",
      "    Stressed       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.54      0.60      0.57        53\n",
      "weighted avg       0.82      0.89      0.85        53\n",
      "\n",
      "Successfully processed User 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.76      0.96      0.85        70\n",
      "     Relaxed       0.50      0.17      0.25        18\n",
      "         Sad       0.00      0.00      0.00         3\n",
      "    Stressed       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.76        99\n",
      "   macro avg       0.57      0.44      0.47        99\n",
      "weighted avg       0.71      0.76      0.71        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.78      0.95      0.85        37\n",
      "     Relaxed       0.80      0.36      0.50        11\n",
      "         Sad       0.00      0.00      0.00         2\n",
      "    Stressed       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.52      0.45      0.46        52\n",
      "weighted avg       0.74      0.77      0.73        52\n",
      "\n",
      "Successfully processed User 20\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.81      0.88      0.85        69\n",
      "     Relaxed       1.00      0.33      0.50         6\n",
      "         Sad       0.57      0.67      0.62         6\n",
      "    Stressed       0.60      0.50      0.55        18\n",
      "\n",
      "    accuracy                           0.77        99\n",
      "   macro avg       0.75      0.60      0.63        99\n",
      "weighted avg       0.77      0.77      0.76        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.61      0.93      0.74        30\n",
      "     Relaxed       0.00      0.00      0.00         2\n",
      "         Sad       0.75      0.50      0.60         6\n",
      "    Stressed       0.25      0.06      0.10        16\n",
      "\n",
      "    accuracy                           0.59        54\n",
      "   macro avg       0.40      0.37      0.36        54\n",
      "weighted avg       0.50      0.59      0.51        54\n",
      "\n",
      "Successfully processed User 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.80      0.90      0.85        70\n",
      "     Relaxed       0.80      0.36      0.50        11\n",
      "         Sad       0.00      0.00      0.00         3\n",
      "    Stressed       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.77        99\n",
      "   macro avg       0.55      0.47      0.49        99\n",
      "weighted avg       0.74      0.77      0.74        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.86      0.84        36\n",
      "     Relaxed       1.00      0.40      0.57         5\n",
      "         Sad       0.00      0.00      0.00         2\n",
      "    Stressed       0.58      0.78      0.67         9\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.60      0.51      0.52        52\n",
      "weighted avg       0.76      0.77      0.75        52\n",
      "\n",
      "Successfully processed User 22\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.89      0.89        57\n",
      "     Relaxed       0.73      0.92      0.81        12\n",
      "         Sad       0.82      0.60      0.69        15\n",
      "    Stressed       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.86        99\n",
      "   macro avg       0.84      0.84      0.83        99\n",
      "weighted avg       0.86      0.86      0.86        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.78      0.89      0.83        28\n",
      "     Relaxed       0.40      0.50      0.44         8\n",
      "         Sad       1.00      0.44      0.62         9\n",
      "    Stressed       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.80      0.63      0.67        48\n",
      "weighted avg       0.77      0.73      0.73        48\n",
      "\n",
      "Successfully processed User 23\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.94      0.96      0.95        79\n",
      "     Relaxed       0.57      0.50      0.53         8\n",
      "         Sad       1.00      0.60      0.75         5\n",
      "    Stressed       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.91        99\n",
      "   macro avg       0.85      0.77      0.79        99\n",
      "weighted avg       0.91      0.91      0.91        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.85      1.00      0.92        39\n",
      "     Relaxed       1.00      0.17      0.29         6\n",
      "    Stressed       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.95      0.59      0.65        50\n",
      "weighted avg       0.88      0.86      0.83        50\n",
      "\n",
      "Successfully processed User 24\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.79      0.94      0.86        63\n",
      "     Relaxed       1.00      0.45      0.62        11\n",
      "         Sad       0.50      0.50      0.50         4\n",
      "    Stressed       0.80      0.57      0.67        21\n",
      "\n",
      "    accuracy                           0.79        99\n",
      "   macro avg       0.77      0.62      0.66        99\n",
      "weighted avg       0.80      0.79      0.78        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.88      0.94      0.91        31\n",
      "     Relaxed       0.40      0.67      0.50         3\n",
      "         Sad       0.00      0.00      0.00         3\n",
      "    Stressed       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.55      0.61      0.57        49\n",
      "weighted avg       0.80      0.84      0.82        49\n",
      "\n",
      "Successfully processed User 25\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.85      0.92      0.88        65\n",
      "     Relaxed       0.80      0.67      0.73         6\n",
      "         Sad       0.62      0.62      0.62         8\n",
      "    Stressed       0.73      0.55      0.63        20\n",
      "\n",
      "    accuracy                           0.81        99\n",
      "   macro avg       0.75      0.69      0.72        99\n",
      "weighted avg       0.80      0.81      0.80        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.70      1.00      0.82        30\n",
      "     Relaxed       1.00      1.00      1.00         2\n",
      "         Sad       0.00      0.00      0.00         5\n",
      "    Stressed       0.67      0.29      0.40        14\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.59      0.57      0.56        51\n",
      "weighted avg       0.63      0.71      0.63        51\n",
      "\n",
      "Successfully processed User 26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.92      0.91      0.91        64\n",
      "     Relaxed       0.73      0.76      0.74        21\n",
      "         Sad       1.00      1.00      1.00         2\n",
      "    Stressed       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.89        99\n",
      "   macro avg       0.91      0.92      0.91        99\n",
      "weighted avg       0.89      0.89      0.89        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.91      0.97      0.94        32\n",
      "     Relaxed       0.80      0.57      0.67         7\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.65      0.64      0.64        48\n",
      "weighted avg       0.87      0.90      0.88        48\n",
      "\n",
      "Successfully processed User 27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.83      0.95      0.89        65\n",
      "     Relaxed       1.00      0.29      0.44         7\n",
      "         Sad       0.88      0.88      0.88        16\n",
      "    Stressed       0.83      0.45      0.59        11\n",
      "\n",
      "    accuracy                           0.84        99\n",
      "   macro avg       0.88      0.64      0.70        99\n",
      "weighted avg       0.85      0.84      0.82        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.77      1.00      0.87        30\n",
      "     Relaxed       0.00      0.00      0.00         3\n",
      "         Sad       1.00      0.75      0.86        12\n",
      "    Stressed       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.69      0.59      0.62        53\n",
      "weighted avg       0.81      0.83      0.80        53\n",
      "\n",
      "Successfully processed User 28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.89      0.99      0.94        85\n",
      "     Relaxed       1.00      0.33      0.50         9\n",
      "    Stressed       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.89        99\n",
      "   macro avg       0.80      0.51      0.57        99\n",
      "weighted avg       0.88      0.89      0.87        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.91      0.98      0.94        41\n",
      "     Relaxed       1.00      0.20      0.33         5\n",
      "    Stressed       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.90        48\n",
      "   macro avg       0.86      0.73      0.69        48\n",
      "weighted avg       0.91      0.90      0.87        48\n",
      "\n",
      "Successfully processed User 29\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.82      0.99      0.90        67\n",
      "     Relaxed       0.90      0.64      0.75        14\n",
      "         Sad       0.00      0.00      0.00         1\n",
      "    Stressed       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.83        99\n",
      "   macro avg       0.65      0.51      0.55        99\n",
      "weighted avg       0.84      0.83      0.81        99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.93      0.88      0.90        43\n",
      "     Relaxed       0.62      1.00      0.77         5\n",
      "    Stressed       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.85        55\n",
      "   macro avg       0.74      0.82      0.76        55\n",
      "weighted avg       0.87      0.85      0.86        55\n",
      "\n",
      "Successfully processed User 30\n",
      "\n",
      "Final Results:\n",
      "    User ID  Accuracy (All)  F1 Score (All)  Accuracy (Opportune)  \\\n",
      "0         1        0.828283        0.801140              0.800000   \n",
      "1         2        0.878788        0.873872              0.860000   \n",
      "2         3        0.777778        0.771050              0.836364   \n",
      "3         4        0.797980        0.759483              0.730769   \n",
      "4         5        0.737374        0.713089              0.785714   \n",
      "5         6        0.818182        0.802330              0.849057   \n",
      "6         7        0.777778        0.750626              0.770833   \n",
      "7         8        0.919192        0.916678              0.938776   \n",
      "8         9        0.737374        0.737672              0.759259   \n",
      "9        10        0.787879        0.772916              0.780000   \n",
      "10       11        0.797980        0.773921              0.830189   \n",
      "11       12        0.848485        0.834743              0.857143   \n",
      "12       13        0.797980        0.774772              0.800000   \n",
      "13       14        0.797980        0.775248              0.740000   \n",
      "14       15        0.767677        0.728983              0.631579   \n",
      "15       16        0.828283        0.821026              0.781818   \n",
      "16       17        0.777778        0.772449              0.725490   \n",
      "17       18        0.868687        0.844586              0.860000   \n",
      "18       19        0.929293        0.907879              0.886792   \n",
      "19       20        0.757576        0.707282              0.769231   \n",
      "20       21        0.767677        0.757261              0.592593   \n",
      "21       22        0.767677        0.744390              0.769231   \n",
      "22       23        0.858586        0.855747              0.729167   \n",
      "23       24        0.909091        0.905051              0.860000   \n",
      "24       25        0.787879        0.775198              0.836735   \n",
      "25       26        0.808081        0.800889              0.705882   \n",
      "26       27        0.888889        0.889743              0.895833   \n",
      "27       28        0.838384        0.819729              0.830189   \n",
      "28       29        0.888889        0.865708              0.895833   \n",
      "29       30        0.828283        0.809932              0.854545   \n",
      "\n",
      "    F1 Score (Opportune)  Opportune Moments Count  \n",
      "0               0.784512                      246  \n",
      "1               0.853846                      248  \n",
      "2               0.832165                      271  \n",
      "3               0.679356                      256  \n",
      "4               0.773219                      277  \n",
      "5               0.841563                      264  \n",
      "6               0.778571                      238  \n",
      "7               0.939885                      243  \n",
      "8               0.756635                      266  \n",
      "9               0.735043                      250  \n",
      "10              0.831612                      263  \n",
      "11              0.801463                      244  \n",
      "12              0.748376                      249  \n",
      "13              0.703810                      248  \n",
      "14              0.568437                      282  \n",
      "15              0.785243                      272  \n",
      "16              0.720825                      253  \n",
      "17              0.813763                      249  \n",
      "18              0.852824                      261  \n",
      "19              0.732411                      260  \n",
      "20              0.505653                      270  \n",
      "21              0.750371                      257  \n",
      "22              0.725570                      239  \n",
      "23              0.825050                      247  \n",
      "24              0.816909                      242  \n",
      "25              0.632501                      255  \n",
      "26              0.880348                      236  \n",
      "27              0.802387                      262  \n",
      "28              0.871977                      240  \n",
      "29              0.855611                      274  \n"
     ]
    }
   ],
   "source": [
    "# Main execution for all users\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize a list to store results for all users\n",
    "    results = []\n",
    "    \n",
    "    # Define features for detecting opportune moments and for training the model\n",
    "    opportune_features = [ \"EMG_z\",\"GSR\",\"BVP\" ]  # Features used for detecting opportune moments\n",
    "    model_features = [\"ECG\", \"EMG_c\", \"EMG_t\",\"Resp\", \"Skin_Temp\"]  # Features used for training the model\n",
    "    \n",
    "    # Loop through all 30 users\n",
    "    for user_id in range(1, 31):  # Assuming user IDs are from 1 to 30\n",
    "        try:\n",
    "           # Load data\n",
    "            physio_data = load_physiological_data(f\"sub{user_id}_DAQ.txt\")\n",
    "            va_data = load_valence_arousal_data(f\"sub{user_id}_joystick.txt\")\n",
    "            \n",
    "          # Preprocess and align data\n",
    "            physio_segmented, va_segmented = preprocess_data(physio_data, va_data)\n",
    "            merged_data = pd.merge(physio_segmented, va_segmented, on=\"window\", how=\"inner\")\n",
    "            \n",
    "            # Map valence-arousal to emotion classes\n",
    "            merged_data[\"emotion\"] = merged_data.apply(\n",
    "                lambda row: map_to_emotion_classes(row[\"valence\"], row[\"arousal\"]), \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Prepare features (X) and targets (y)\n",
    "            X_opportune = merged_data[opportune_features].apply(zscore).values\n",
    "            X_model = merged_data[model_features]\n",
    "            y = merged_data[\"emotion\"]\n",
    "            \n",
    "            # Split data into train and test sets (baseline model)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_model, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train and evaluate baseline model - with all features at all moments\n",
    "            accuracy_all, f1_all = train_and_evaluate_classifier(\n",
    "                X_train, X_test, y_train, y_test\n",
    "            )\n",
    "            \n",
    "            # Detect opportune moments\n",
    "            change_scores = compute_rulsif_change_scores(X_opportune)\n",
    "            opportune_moments = label_opportune_moments(change_scores)\n",
    "            \n",
    "            # Filter data for opportune moments\n",
    "            opportune_data = merged_data[merged_data[\"window\"].isin(opportune_moments)]\n",
    "            \n",
    "            # Skip user if no opportune moments found\n",
    "            if len(opportune_data) == 0:\n",
    "                print(f\"No opportune moments found for User {user_id}. Skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Prepare features for opportune moments\n",
    "            X_opportune_train = opportune_data[model_features]\n",
    "            y_opportune = opportune_data[\"emotion\"]\n",
    "            \n",
    "            # Check if we have enough samples for splitting\n",
    "            MIN_SAMPLES = 5  # Minimum samples required\n",
    "            if len(X_opportune_train) < MIN_SAMPLES:\n",
    "                print(f\"Only {len(X_opportune_train)} opportune moments for User {user_id}. Skipping...\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Split data into train and test sets for opportune moments\n",
    "                X_train_opportune, X_test_opportune, y_train_opportune, y_test_opportune = train_test_split(\n",
    "                    X_opportune_train, y_opportune, test_size=0.2, random_state=42\n",
    "                )\n",
    "                \n",
    "                # Train and evaluate opportune moments model\n",
    "                accuracy_opportune, f1_opportune = train_and_evaluate_classifier(\n",
    "                    X_train_opportune, X_test_opportune, y_train_opportune, y_test_opportune\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing User {user_id}: {str(e)}. Skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Store results for the current user\n",
    "            results.append({\n",
    "                \"User ID\": user_id,\n",
    "                \"Accuracy (All)\": accuracy_all,\n",
    "                \"F1 Score (All)\": f1_all,\n",
    "                \"Accuracy (Opportune)\": accuracy_opportune,\n",
    "                \"F1 Score (Opportune)\": f1_opportune,\n",
    "                \"Opportune Moments Count\": len(opportune_moments)\n",
    "            })\n",
    "            \n",
    "            print(f\"Successfully processed User {user_id}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data files for User {user_id} not found. Skipping...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing User {user_id}: {str(e)}. Skipping...\")\n",
    "            continue\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv(\"emotion_classification_results_robust.csv\", index=False)\n",
    "    \n",
    "    # Print the results table\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
